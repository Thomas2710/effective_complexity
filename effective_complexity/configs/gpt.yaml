learning_rate: 0.001
num_epochs: 100
num_samples: 10000
hidden_units: 64
input_size: 3
hidden_sizes: [64,32,64]
output_size: 3
DIMS: 3
COV: 1
MU: 0
BATCH_SIZE: 256
model_id: gpt2
